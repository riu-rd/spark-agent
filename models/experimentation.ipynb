{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFQ_FP6ijE3D",
        "outputId": "4d52e660-ed40-484d-e581-252f0080c26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/transactions_fixed.csv') # upload transactions.csv on your personal drive\n",
        "df1 = pd.read_csv('/content/drive/My Drive/transactions_fixed.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4YkWTt19Znn"
      },
      "source": [
        "##**Old Code** (do not use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1u1cQHnCCFq",
        "outputId": "a5444e6d-15a4-4b84-846d-42b785078c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ TRYBE Fintech AI System - Production Ready\n",
            "==================================================\n",
            "============================================================\n",
            "TRYBE DISCREPANCY DETECTOR - REAL DATA\n",
            "============================================================\n",
            "Loaded 10000 transactions\n",
            "Columns: ['transaction_id', 'user_id', 'timestamp_initiated', 'amount', 'transaction_type', 'recipient_type', 'recipient_account_id', 'recipient_bank_name_or_ewallet', 'device_id', 'location_coordinates', 'simulated_network_latency', 'status_timestamp_1', 'status_1', 'status_timestamp_2', 'status_2', 'status_timestamp_3', 'status_3', 'status_timestamp_4', 'status_4', 'expected_completion_time', 'is_floating_cash', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'is_retry_successful', 'manual_escalation_needed', 'transaction_types', 'recipient_bank_name/e-wallet_name']\n",
            "\n",
            "Dataset Overview:\n",
            "- Date range: 2023-03-24 15:02:45 to 2024-07-31 16:03:55\n",
            "- Amount range: $10.00 to $25000.00\n",
            "- Transaction types: ['Bank to e-Wallet (Maya)' 'Auto-Reversal Processed'\n",
            " 'Internal Vybe App Transfer' 'Bills Payment (via Vybe Wallet)'\n",
            " 'Bank to Bank (InstaPay)' 'Cash-In via Partner Outlet'\n",
            " 'QR Payment (Merchant)' 'QR Payment (P2P)' 'Cash-Out via ATM or OTC'\n",
            " 'Internal Cashback Credit' 'Vybe Wallet to ShopeePay'\n",
            " 'Bank to Bank (PESONet)' 'Vybe Wallet to GCash' 'Auto-Retry Triggered'\n",
            " 'Vybe Wallet to Bank (BPI)' 'Vybe Wallet to Maya'\n",
            " 'Bank to e-Wallet (ShopeePay)' 'Bills Payment (via BPI Linked)'\n",
            " 'Vybe Wallet to Vybe Wallet' 'Scheduled Transfer (Future Dated)'\n",
            " 'Manual Escalation Triggered' 'Bank to e-Wallet (GCash)'\n",
            " 'BPI to Vybe Wallet' nan 'Reversed (User Cancelled)']\n",
            "- Final statuses: status_4\n",
            "Credit Confirmed (Recipient)    6870\n",
            "Failed (Timeout)                1093\n",
            "Failed (Network Error)          1016\n",
            "Reversed (User Cancelled)        974\n",
            "Reversed (System)                  7\n",
            "Name: count, dtype: int64\n",
            "Running discrepancy detection...\n",
            "\n",
            "Detection Results:\n",
            "- Total transactions analyzed: 10000\n",
            "- Flagged as discrepancies: 8867\n",
            "- Percentage flagged: 88.67%\n",
            "- Actual floating cash (ground truth): 501\n",
            "- Detection Precision: 0.051\n",
            "- Detection Recall: 0.898\n",
            "\n",
            "üîç Flagged Transactions Sample:\n",
            "                          transaction_id     user_id   amount  \\\n",
            "0   fedcba98-7654-3210-abcd-ef0123456789   user_7758   103.35   \n",
            "1   a8b7c6d5-e4f3-2c1b-a0d9-8e7f6a5b4c3d  user_19632  1500.00   \n",
            "2   b36ce980-b772-46a4-9e32-b7e1ce171120  user_38848   890.10   \n",
            "4   90e664ee-6998-4384-95a9-4b8c7fc444a1  user_43694   750.25   \n",
            "5   9099e078-45a7-4b77-b9c6-c954e3d64c1c  user_65306  2598.63   \n",
            "6   3411b439-d3e8-4674-87d2-64f3d2f93d39   user_7368  9604.75   \n",
            "7   a8204683-16a5-4899-b1d6-b072c47a329d   user_3640  1880.61   \n",
            "8   c7075217-09a8-4229-87c2-ec0645607b22      user_5    50.00   \n",
            "9   d16a8277-2f54-4fb9-a03a-0e9e95261d76   user_8112  3374.88   \n",
            "10  22ed5080-6ac3-4a16-950c-e2f7b8801940  user_48529    83.47   \n",
            "\n",
            "              transaction_type                      status_4  \\\n",
            "0      Bank to e-Wallet (Maya)  Credit Confirmed (Recipient)   \n",
            "1      Auto-Reversal Processed  Credit Confirmed (Recipient)   \n",
            "2   Internal Vybe App Transfer              Failed (Timeout)   \n",
            "4      Bank to Bank (InstaPay)  Credit Confirmed (Recipient)   \n",
            "5   Cash-In via Partner Outlet     Reversed (User Cancelled)   \n",
            "6        QR Payment (Merchant)  Credit Confirmed (Recipient)   \n",
            "7             QR Payment (P2P)  Credit Confirmed (Recipient)   \n",
            "8      Bank to Bank (InstaPay)     Reversed (User Cancelled)   \n",
            "9   Cash-In via Partner Outlet  Credit Confirmed (Recipient)   \n",
            "10     Cash-Out via ATM or OTC  Credit Confirmed (Recipient)   \n",
            "\n",
            "    manual_escalation_needed  floating_duration_minutes  \n",
            "0                      False                          0  \n",
            "1                      False                          0  \n",
            "2                      False                          0  \n",
            "4                      False                          0  \n",
            "5                      False                          0  \n",
            "6                       True                          0  \n",
            "7                      False                          0  \n",
            "8                      False                          0  \n",
            "9                      False                       1165  \n",
            "10                      True                          0  \n",
            "\n",
            "==================================================\n",
            "============================================================\n",
            "TRYBE RISK PREDICTOR - REAL DATA\n",
            "============================================================\n",
            "Loaded 10000 records for risk prediction\n",
            "Target distribution:\n",
            "is_floating_cash\n",
            "False    9499\n",
            "True      501\n",
            "Name: count, dtype: int64\n",
            "Original features requested: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed']\n",
            "Available features in data: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed']\n",
            "Target variable: is_floating_cash\n",
            "Final features being used: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed', 'amount_log', 'is_high_amount', 'is_high_latency', 'hour_of_day', 'day_of_week', 'is_weekend', 'high_risk_combo']\n",
            "Training random_forest model...\n",
            "Training set size: 10000 samples, 16 features\n",
            "Features used: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed', 'amount_log', 'is_high_amount', 'is_high_latency', 'hour_of_day', 'day_of_week', 'is_weekend', 'high_risk_combo']\n",
            "Class distribution: {False: np.int64(9499), True: np.int64(501)}\n",
            "\n",
            "üéØ Model Evaluation Results:\n",
            "Accuracy: 0.9145\n",
            "AUC-ROC: 0.9556\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.91      0.95      1900\n",
            "        True       0.36      0.92      0.52       100\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.68      0.92      0.74      2000\n",
            "weighted avg       0.96      0.91      0.93      2000\n",
            "\n",
            "\n",
            "üìä Top 10 Most Important Features:\n",
            "                           feature  importance\n",
            "5        floating_duration_minutes    0.836327\n",
            "1        simulated_network_latency    0.025686\n",
            "9                       amount_log    0.023548\n",
            "0                           amount    0.021637\n",
            "4   recipient_bank_name_or_ewallet    0.019914\n",
            "2                 transaction_type    0.019914\n",
            "12                     hour_of_day    0.016706\n",
            "3                   recipient_type    0.009177\n",
            "13                     day_of_week    0.007732\n",
            "8         manual_escalation_needed    0.007084\n",
            "\n",
            "üéØ Risk Prediction Example:\n",
            "Transaction ID: fedcba98-7654-3210-abcd-ef0123456789\n",
            "Amount: $103.35\n",
            "Type: Bank to e-Wallet (Maya)\n",
            "Predicted Risk Probability: 0.0068\n",
            "Actual Outcome: Normal\n",
            "\n",
            "‚úÖ TRYBE System Ready for Production!\n",
            "üìä Dataset: 10000 transactions processed\n",
            "üîç Discrepancy Detector: Active\n",
            "üéØ Risk Predictor: random_forest trained\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 1. TRYBE DISCREPANCY DETECTOR\n",
        "# =============================================================================\n",
        "\n",
        "class TRYBEDiscrepancyDetector:\n",
        "    \"\"\"\n",
        "    Detects floating cash transactions where debits occur but credits are delayed/missing.\n",
        "    Revised for transactions_fixed.csv dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.detection_rules = []\n",
        "        # Column mapping for the actual dataset - REVISED\n",
        "        self.column_mapping = {\n",
        "            'transaction_id': 'transaction_id',\n",
        "            'user_id': 'user_id',\n",
        "            'amount': 'amount',\n",
        "            'transaction_type': 'transaction_type',\n",
        "            'recipient_type': 'recipient_type',\n",
        "            'status_4': 'status_4',  # Latest status\n",
        "            'is_floating_cash': 'is_floating_cash',  # Ground truth\n",
        "            'floating_duration_minutes': 'floating_duration_minutes',\n",
        "            'manual_escalation_needed': 'manual_escalation_needed',\n",
        "            'is_fraudulent_attempt': 'is_fraudulent_attempt',\n",
        "            'network_latency': 'simulated_network_latency',\n",
        "            'recipient_bank': 'recipient_bank_name_or_ewallet',  # REVISED: correct column name\n",
        "            'timestamp': 'timestamp_initiated',\n",
        "            'is_cancellation': 'is_cancellation'\n",
        "        }\n",
        "\n",
        "    def load_transaction_data(self, file_path_or_df):\n",
        "        \"\"\"\n",
        "        Load transaction dataset.\n",
        "        \"\"\"\n",
        "        if isinstance(file_path_or_df, str):\n",
        "            df = pd.read_csv(file_path_or_df)\n",
        "        else:\n",
        "            df = file_path_or_df.copy()\n",
        "\n",
        "        print(f\"Loaded {len(df)} transactions\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Basic data validation\n",
        "        print(f\"\\nDataset Overview:\")\n",
        "        print(f\"- Date range: {df['timestamp_initiated'].min()} to {df['timestamp_initiated'].max()}\")\n",
        "        print(f\"- Amount range: ${df['amount'].min():.2f} to ${df['amount'].max():.2f}\")\n",
        "        print(f\"- Transaction types: {df['transaction_type'].unique()}\")\n",
        "        print(f\"- Final statuses: {df['status_4'].value_counts().head()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def is_floating_transaction(self, row):\n",
        "        \"\"\"\n",
        "        Enhanced rule-based function to detect floating cash transactions.\n",
        "        Based on the actual dataset structure and business logic.\n",
        "        \"\"\"\n",
        "\n",
        "        # Rule 1: Check ground truth first (for validation)\n",
        "        # Note: In production, you won't have this column\n",
        "        if hasattr(row, 'is_floating_cash') and pd.notna(row.is_floating_cash):\n",
        "            # This is for validation - remove in production\n",
        "            pass\n",
        "\n",
        "        # Rule 2: Failed transactions are likely floating\n",
        "        if hasattr(row, 'status_4') and pd.notna(row.status_4):\n",
        "            failed_keywords = ['failed', 'timeout', 'error', 'stuck', 'pending']\n",
        "            status_lower = str(row.status_4).lower()\n",
        "            if any(keyword in status_lower for keyword in failed_keywords):\n",
        "                return True\n",
        "\n",
        "        # Rule 3: Manual escalation needed indicates floating cash\n",
        "        if hasattr(row, 'manual_escalation_needed') and row.manual_escalation_needed:\n",
        "            return True\n",
        "\n",
        "        # Rule 4: High network latency + non-completed status\n",
        "        if (hasattr(row, 'simulated_network_latency') and\n",
        "            hasattr(row, 'status_4') and\n",
        "            row.simulated_network_latency > 1000):  # High latency threshold\n",
        "            if 'completed' not in str(row.status_4).lower():\n",
        "                return True\n",
        "\n",
        "        # Rule 5: Large amount transactions with suspicious patterns\n",
        "        if hasattr(row, 'amount') and row.amount > 5000:  # Adjust threshold as needed\n",
        "            if hasattr(row, 'status_4'):\n",
        "                suspicious_statuses = ['processing', 'pending', 'review']\n",
        "                if any(status in str(row.status_4).lower() for status in suspicious_statuses):\n",
        "                    return True\n",
        "\n",
        "        # Rule 6: Specific transaction types that are prone to floating\n",
        "        if hasattr(row, 'transaction_type'):\n",
        "            risky_types = ['Bank to e-Wallet', 'Internal Transfer']  # Add more as needed\n",
        "            if any(risky_type in str(row.transaction_type) for risky_type in risky_types):\n",
        "                if hasattr(row, 'status_4') and 'failed' in str(row.status_4).lower():\n",
        "                    return True\n",
        "\n",
        "        # TODO: Add more custom rules based on your business logic\n",
        "        # Rule 7: Time-based rules (e.g., transactions pending for too long)\n",
        "        # Rule 8: Recipient-specific rules\n",
        "        # Rule 9: Device/location-based anomalies\n",
        "\n",
        "        return False\n",
        "\n",
        "    def detect_discrepancies(self, df):\n",
        "        \"\"\"\n",
        "        Apply discrepancy detection to the entire dataset.\n",
        "        \"\"\"\n",
        "        print(\"Running discrepancy detection...\")\n",
        "\n",
        "        # Apply the detection function to each row\n",
        "        df['detected_discrepancy'] = df.apply(self.is_floating_transaction, axis=1)\n",
        "\n",
        "        # Summary statistics\n",
        "        total_transactions = len(df)\n",
        "        flagged_transactions = df['detected_discrepancy'].sum()\n",
        "        flagged_percentage = (flagged_transactions / total_transactions) * 100\n",
        "\n",
        "        print(f\"\\nDetection Results:\")\n",
        "        print(f\"- Total transactions analyzed: {total_transactions}\")\n",
        "        print(f\"- Flagged as discrepancies: {flagged_transactions}\")\n",
        "        print(f\"- Percentage flagged: {flagged_percentage:.2f}%\")\n",
        "\n",
        "        # Validation against ground truth (if available)\n",
        "        if 'is_floating_cash' in df.columns:\n",
        "            actual_floating = df['is_floating_cash'].sum()\n",
        "            print(f\"- Actual floating cash (ground truth): {actual_floating}\")\n",
        "\n",
        "            # Calculate detection accuracy\n",
        "            if actual_floating > 0:\n",
        "                true_positives = ((df['detected_discrepancy'] == True) &\n",
        "                                (df['is_floating_cash'] == True)).sum()\n",
        "                precision = true_positives / flagged_transactions if flagged_transactions > 0 else 0\n",
        "                recall = true_positives / actual_floating if actual_floating > 0 else 0\n",
        "\n",
        "                print(f\"- Detection Precision: {precision:.3f}\")\n",
        "                print(f\"- Detection Recall: {recall:.3f}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def get_flagged_transactions(self, df):\n",
        "        \"\"\"\n",
        "        Return only the transactions flagged as discrepancies with key details.\n",
        "        \"\"\"\n",
        "        flagged = df[df['detected_discrepancy'] == True].copy()\n",
        "\n",
        "        # Select most relevant columns for review\n",
        "        key_columns = ['transaction_id', 'user_id', 'amount', 'transaction_type',\n",
        "                      'status_4', 'manual_escalation_needed', 'floating_duration_minutes']\n",
        "\n",
        "        # Only include columns that exist in the dataset\n",
        "        available_columns = [col for col in key_columns if col in flagged.columns]\n",
        "\n",
        "        return flagged[available_columns]\n",
        "\n",
        "# =============================================================================\n",
        "# 2. TRYBE RISK PREDICTOR\n",
        "# =============================================================================\n",
        "\n",
        "class TRYBERiskPredictor:\n",
        "    \"\"\"\n",
        "    Predicts probability that a transaction will get stuck or become floating cash.\n",
        "    Revised for transactions_fixed.csv dataset features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_type='random_forest'):\n",
        "        self.model_type = model_type\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_columns = None\n",
        "        self.target_column = None\n",
        "\n",
        "    def load_data(self, file_path_or_df):\n",
        "        \"\"\"\n",
        "        Load dataset for risk prediction.\n",
        "        \"\"\"\n",
        "        if isinstance(file_path_or_df, str):\n",
        "            df = pd.read_csv(file_path_or_df)\n",
        "        else:\n",
        "            df = file_path_or_df.copy()\n",
        "\n",
        "        print(f\"Loaded {len(df)} records for risk prediction\")\n",
        "        print(f\"Target distribution:\")\n",
        "        if 'is_floating_cash' in df.columns:\n",
        "            print(df['is_floating_cash'].value_counts())\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess_data(self, df, feature_columns=None, target_column=None):\n",
        "        \"\"\"\n",
        "        Preprocess the data for machine learning using the actual dataset structure.\n",
        "        REVISED: Updated feature columns to match actual dataset\n",
        "        \"\"\"\n",
        "        df_processed = df.copy()\n",
        "\n",
        "        # Set feature columns based on actual dataset - REVISED\n",
        "        if feature_columns is None:\n",
        "            feature_columns = [\n",
        "                'amount',                           # Transaction amount\n",
        "                'simulated_network_latency',        # Network conditions\n",
        "                'transaction_type',                 # Type of transaction\n",
        "                'recipient_type',                   # Type of recipient\n",
        "                'recipient_bank_name_or_ewallet',   # Bank/e-wallet - REVISED: correct column name\n",
        "                'floating_duration_minutes',        # Historical floating duration\n",
        "                'is_fraudulent_attempt',            # Fraud indicator\n",
        "                'is_cancellation',                  # Cancellation flag\n",
        "                'manual_escalation_needed'          # Escalation needed\n",
        "            ]\n",
        "\n",
        "        # Set target column\n",
        "        if target_column is None:\n",
        "            target_column = 'is_floating_cash'  # Your ground truth column\n",
        "\n",
        "        # Filter to only available columns\n",
        "        available_features = [col for col in feature_columns if col in df_processed.columns]\n",
        "\n",
        "        print(f\"Original features requested: {feature_columns}\")\n",
        "        print(f\"Available features in data: {available_features}\")\n",
        "        print(f\"Target variable: {target_column}\")\n",
        "\n",
        "        # Create engineered features BEFORE setting self.feature_columns\n",
        "        df_processed = self._create_engineered_features(df_processed)\n",
        "\n",
        "        # Now add engineered features to available_features if they exist\n",
        "        engineered_features = ['amount_log', 'is_high_amount', 'is_high_latency',\n",
        "                              'hour_of_day', 'day_of_week', 'is_weekend', 'high_risk_combo']\n",
        "\n",
        "        for feature in engineered_features:\n",
        "            if feature in df_processed.columns:\n",
        "                available_features.append(feature)\n",
        "\n",
        "        # Set final feature columns\n",
        "        self.feature_columns = available_features\n",
        "        self.target_column = target_column\n",
        "\n",
        "        print(f\"Final features being used: {self.feature_columns}\")\n",
        "\n",
        "        # Handle missing values\n",
        "        for col in self.feature_columns:\n",
        "            if df_processed[col].dtype in ['object', 'category']:\n",
        "                df_processed[col] = df_processed[col].fillna('unknown')\n",
        "            else:\n",
        "                df_processed[col] = df_processed[col].fillna(df_processed[col].median())\n",
        "\n",
        "        # Encode categorical variables - REVISED: updated column name\n",
        "        categorical_features = ['transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet']\n",
        "        for col in categorical_features:\n",
        "            if col in df_processed.columns and col in self.feature_columns:\n",
        "                le = LabelEncoder()\n",
        "                df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
        "                self.label_encoders[col] = le\n",
        "\n",
        "        return df_processed\n",
        "\n",
        "    def _create_engineered_features(self, df):\n",
        "        \"\"\"\n",
        "        Create additional features from the dataset.\n",
        "        Returns df with new features, but doesn't modify self.feature_columns\n",
        "        \"\"\"\n",
        "        # Amount-based features\n",
        "        if 'amount' in df.columns:\n",
        "            df['amount_log'] = np.log1p(df['amount'])  # Log transform for skewed amounts\n",
        "            df['is_high_amount'] = (df['amount'] > df['amount'].quantile(0.9)).astype(int)\n",
        "\n",
        "        # Network latency features\n",
        "        if 'simulated_network_latency' in df.columns:\n",
        "            df['is_high_latency'] = (df['simulated_network_latency'] > 1000).astype(int)\n",
        "\n",
        "        # Time-based features (if timestamps are available)\n",
        "        if 'timestamp_initiated' in df.columns:\n",
        "            try:\n",
        "                df['timestamp_initiated'] = pd.to_datetime(df['timestamp_initiated'])\n",
        "                df['hour_of_day'] = df['timestamp_initiated'].dt.hour\n",
        "                df['day_of_week'] = df['timestamp_initiated'].dt.dayofweek\n",
        "                df['is_weekend'] = (df['day_of_week'].isin([5, 6])).astype(int)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not process timestamp_initiated: {e}\")\n",
        "\n",
        "        # Risk combination features\n",
        "        if 'is_fraudulent_attempt' in df.columns and 'manual_escalation_needed' in df.columns:\n",
        "            df['high_risk_combo'] = (df['is_fraudulent_attempt'] | df['manual_escalation_needed']).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def get_model(self):\n",
        "        \"\"\"\n",
        "        Initialize the ML model. Easily swappable model types.\n",
        "        \"\"\"\n",
        "        if self.model_type == 'random_forest':\n",
        "            return RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=10,\n",
        "                min_samples_split=10,\n",
        "                random_state=42,\n",
        "                class_weight='balanced'  # Handle imbalanced data\n",
        "            )\n",
        "        elif self.model_type == 'logistic_regression':\n",
        "            return LogisticRegression(\n",
        "                random_state=42,\n",
        "                class_weight='balanced',\n",
        "                max_iter=1000\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
        "\n",
        "    def train_model(self, df_processed):\n",
        "        \"\"\"\n",
        "        Train the risk prediction model.\n",
        "        \"\"\"\n",
        "        print(f\"Training {self.model_type} model...\")\n",
        "\n",
        "        # Double-check that all feature columns exist in the processed dataframe\n",
        "        missing_features = [col for col in self.feature_columns if col not in df_processed.columns]\n",
        "        if missing_features:\n",
        "            print(f\"Warning: Missing features {missing_features}, removing from feature list\")\n",
        "            self.feature_columns = [col for col in self.feature_columns if col in df_processed.columns]\n",
        "\n",
        "        # Prepare features and target\n",
        "        X = df_processed[self.feature_columns]\n",
        "        y = df_processed[self.target_column]\n",
        "\n",
        "        print(f\"Training set size: {len(X)} samples, {len(self.feature_columns)} features\")\n",
        "        print(f\"Features used: {self.feature_columns}\")\n",
        "        print(f\"Class distribution: {dict(y.value_counts())}\")\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Train the model\n",
        "        self.model = self.get_model()\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate the model\n",
        "        self.evaluate_model(X_test_scaled, y_test)\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Evaluate model performance with detailed metrics.\n",
        "        \"\"\"\n",
        "        # Make predictions\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "        print(f\"\\nüéØ Model Evaluation Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"AUC-ROC: {auc:.4f}\")\n",
        "        print(f\"\\nDetailed Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        # Feature importance (for tree-based models)\n",
        "        if hasattr(self.model, 'feature_importances_'):\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': self.feature_columns,\n",
        "                'importance': self.model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(f\"\\nüìä Top 10 Most Important Features:\")\n",
        "            print(feature_importance.head(10))\n",
        "\n",
        "    def predict_risk(self, transaction_data):\n",
        "        \"\"\"\n",
        "        Predict risk probability for new transaction(s).\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet. Call train_model() first.\")\n",
        "\n",
        "        # Handle single transaction (dict)\n",
        "        if isinstance(transaction_data, dict):\n",
        "            transaction_data = pd.DataFrame([transaction_data])\n",
        "\n",
        "        # Create engineered features for new data\n",
        "        transaction_data = self._create_engineered_features(transaction_data)\n",
        "\n",
        "        # Ensure we only use features that exist in both training and prediction data\n",
        "        available_features = [col for col in self.feature_columns if col in transaction_data.columns]\n",
        "\n",
        "        if len(available_features) != len(self.feature_columns):\n",
        "            missing = set(self.feature_columns) - set(available_features)\n",
        "            print(f\"Warning: Missing features for prediction: {missing}\")\n",
        "            print(f\"Using available features: {available_features}\")\n",
        "\n",
        "        # Preprocess categorical features\n",
        "        for col in available_features:\n",
        "            if col in self.label_encoders:\n",
        "                le = self.label_encoders[col]\n",
        "                transaction_data[col] = transaction_data[col].astype(str)\n",
        "                transaction_data[col] = transaction_data[col].apply(\n",
        "                    lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
        "                )\n",
        "\n",
        "        # Handle missing values for new data\n",
        "        for col in available_features:\n",
        "            if transaction_data[col].dtype in ['object', 'category']:\n",
        "                transaction_data[col] = transaction_data[col].fillna('unknown')\n",
        "            else:\n",
        "                transaction_data[col] = transaction_data[col].fillna(0)  # Use 0 for missing numerical features\n",
        "\n",
        "        # Select only available features and scale\n",
        "        X = transaction_data[available_features]\n",
        "\n",
        "        # If we're missing features, pad with zeros\n",
        "        if len(available_features) < len(self.feature_columns):\n",
        "            # Create a dataframe with all required features, filling missing ones with 0\n",
        "            X_full = pd.DataFrame(0, index=X.index, columns=self.feature_columns)\n",
        "            X_full[available_features] = X\n",
        "            X = X_full\n",
        "\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        # Predict probabilities\n",
        "        risk_probabilities = self.model.predict_proba(X_scaled)[:, 1]\n",
        "\n",
        "        return risk_probabilities[0] if len(risk_probabilities) == 1 else risk_probabilities\n",
        "\n",
        "# =============================================================================\n",
        "# 3. MAIN INTEGRATION & DEMO FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def demo_discrepancy_detection(df_transactions):\n",
        "    \"\"\"\n",
        "    Demo function for the discrepancy detector using actual data.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRYBE DISCREPANCY DETECTOR - REAL DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize and run detector\n",
        "    detector = TRYBEDiscrepancyDetector()\n",
        "    detector.load_transaction_data(df_transactions)\n",
        "    df_with_flags = detector.detect_discrepancies(df_transactions.copy())\n",
        "\n",
        "    print(f\"\\nüîç Flagged Transactions Sample:\")\n",
        "    flagged = detector.get_flagged_transactions(df_with_flags)\n",
        "    print(flagged.head(10))\n",
        "\n",
        "    return detector, df_with_flags\n",
        "\n",
        "def demo_risk_prediction(df_transactions):\n",
        "    \"\"\"\n",
        "    Demo function for the risk predictor using actual data.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TRYBE RISK PREDICTOR - REAL DATA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize predictor\n",
        "    predictor = TRYBERiskPredictor(model_type='random_forest')\n",
        "\n",
        "    # Load and preprocess data\n",
        "    df = predictor.load_data(df_transactions)\n",
        "    df_processed = predictor.preprocess_data(df)\n",
        "\n",
        "    # Train the model\n",
        "    trained_model = predictor.train_model(df_processed)\n",
        "\n",
        "    # Test prediction on a sample transaction\n",
        "    sample_transaction = df_transactions.iloc[0].to_dict()\n",
        "\n",
        "    try:\n",
        "        risk_prob = predictor.predict_risk(sample_transaction)\n",
        "\n",
        "        print(f\"\\nüéØ Risk Prediction Example:\")\n",
        "        print(f\"Transaction ID: {sample_transaction.get('transaction_id', 'N/A')}\")\n",
        "        print(f\"Amount: ${sample_transaction.get('amount', 0):.2f}\")\n",
        "        print(f\"Type: {sample_transaction.get('transaction_type', 'N/A')}\")\n",
        "        print(f\"Predicted Risk Probability: {risk_prob:.4f}\")\n",
        "        print(f\"Actual Outcome: {'Floating' if sample_transaction.get('is_floating_cash', False) else 'Normal'}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in prediction example: {e}\")\n",
        "        print(\"Model trained successfully but prediction example failed\")\n",
        "\n",
        "    return predictor, trained_model\n",
        "\n",
        "def main(transaction_df=None):\n",
        "    \"\"\"\n",
        "    Main function to run both TRYBE components with actual data.\n",
        "    \"\"\"\n",
        "    print(\"üöÄ TRYBE Fintech AI System - Production Ready\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    if transaction_df is None:\n",
        "        print(\"‚ùå No transaction data provided. Please load transactions_fixed.csv\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Run discrepancy detection\n",
        "    detector, flagged_df = demo_discrepancy_detection(transaction_df)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "    # Run risk prediction\n",
        "    predictor, model = demo_risk_prediction(transaction_df)\n",
        "\n",
        "    print(f\"\\n‚úÖ TRYBE System Ready for Production!\")\n",
        "    print(f\"üìä Dataset: {len(transaction_df)} transactions processed\")\n",
        "    print(f\"üîç Discrepancy Detector: Active\")\n",
        "    print(f\"üéØ Risk Predictor: {predictor.model_type} trained\")\n",
        "\n",
        "    return detector, predictor, model\n",
        "\n",
        "# =============================================================================\n",
        "# 4. HACKATHON UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def quick_setup(data_path=\"transactions_fixed.csv\", use_gdrive=False, file_id=None):\n",
        "    \"\"\"\n",
        "    Ultra-fast setup for hackathon use with actual dataset.\n",
        "    REVISED: Updated default filename to match actual dataset\n",
        "    \"\"\"\n",
        "    print(\"‚ö° TRYBE Quick Setup - Hackathon Mode\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Load data\n",
        "    if use_gdrive and file_id:\n",
        "        try:\n",
        "            import gdown\n",
        "        except ImportError:\n",
        "            import subprocess\n",
        "            subprocess.check_call([\"pip\", \"install\", \"gdown\"])\n",
        "            import gdown\n",
        "\n",
        "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "        print(f\"üì• Downloading from Google Drive...\")\n",
        "        gdown.download(url, \"transactions_fixed.csv\", quiet=False)\n",
        "        data_path = \"transactions_fixed.csv\"\n",
        "\n",
        "    # Load the dataset\n",
        "    print(f\"üìä Loading {data_path}...\")\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "    # Run the full system\n",
        "    return main(df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the actual dataset - REVISED: Updated filename\n",
        "    df_transactions = pd.read_csv(\"/content/drive/My Drive/transactions_fixed.csv\")\n",
        "\n",
        "    # Run the system\n",
        "    detector, predictor, model = main(df_transactions)\n",
        "\n",
        "    # For Google Drive usage:\n",
        "    # detector, predictor, model = quick_setup(use_gdrive=True, file_id=\"YOUR_FILE_ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdODO4fmFC1G",
        "outputId": "71713ee7-d4ed-4cac-cb8e-bad965c2fc10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 transactions\n",
            "Columns: ['transaction_id', 'user_id', 'timestamp_initiated', 'amount', 'transaction_type', 'recipient_type', 'recipient_account_id', 'recipient_bank_name_or_ewallet', 'device_id', 'location_coordinates', 'simulated_network_latency', 'status_timestamp_1', 'status_1', 'status_timestamp_2', 'status_2', 'status_timestamp_3', 'status_3', 'status_timestamp_4', 'status_4', 'expected_completion_time', 'is_floating_cash', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'is_retry_successful', 'manual_escalation_needed', 'transaction_types', 'recipient_bank_name/e-wallet_name']\n",
            "\n",
            "Dataset Overview:\n",
            "- Date range: 2023-03-24 15:02:45 to 2024-07-31 16:03:55\n",
            "- Amount range: $10.00 to $25000.00\n",
            "- Transaction types: ['Bank to e-Wallet (Maya)' 'Auto-Reversal Processed'\n",
            " 'Internal Vybe App Transfer' 'Bills Payment (via Vybe Wallet)'\n",
            " 'Bank to Bank (InstaPay)' 'Cash-In via Partner Outlet'\n",
            " 'QR Payment (Merchant)' 'QR Payment (P2P)' 'Cash-Out via ATM or OTC'\n",
            " 'Internal Cashback Credit' 'Vybe Wallet to ShopeePay'\n",
            " 'Bank to Bank (PESONet)' 'Vybe Wallet to GCash' 'Auto-Retry Triggered'\n",
            " 'Vybe Wallet to Bank (BPI)' 'Vybe Wallet to Maya'\n",
            " 'Bank to e-Wallet (ShopeePay)' 'Bills Payment (via BPI Linked)'\n",
            " 'Vybe Wallet to Vybe Wallet' 'Scheduled Transfer (Future Dated)'\n",
            " 'Manual Escalation Triggered' 'Bank to e-Wallet (GCash)'\n",
            " 'BPI to Vybe Wallet' nan 'Reversed (User Cancelled)']\n",
            "- Final statuses: status_4\n",
            "Credit Confirmed (Recipient)    6870\n",
            "Failed (Timeout)                1093\n",
            "Failed (Network Error)          1016\n",
            "Reversed (User Cancelled)        974\n",
            "Reversed (System)                  7\n",
            "Name: count, dtype: int64\n",
            "Running discrepancy detection...\n",
            "\n",
            "Detection Results:\n",
            "- Total transactions analyzed: 10000\n",
            "- Flagged as discrepancies: 8867\n",
            "- Percentage flagged: 88.67%\n",
            "- Actual floating cash (ground truth): 501\n",
            "- Detection Precision: 0.051\n",
            "- Detection Recall: 0.898\n",
            "Found 8867 suspicious transactions\n"
          ]
        }
      ],
      "source": [
        "# SAMPLE DEMO 2 (Discrepancy Detector)\n",
        "\n",
        "# Initialize detector\n",
        "detector = TRYBEDiscrepancyDetector()\n",
        "\n",
        "# Load and analyze data\n",
        "df = detector.load_transaction_data(\"/content/drive/My Drive/transactions_fixed.csv\")\n",
        "df_with_flags = detector.detect_discrepancies(df)\n",
        "\n",
        "# Get flagged transactions\n",
        "flagged_transactions = detector.get_flagged_transactions(df_with_flags)\n",
        "print(f\"Found {len(flagged_transactions)} suspicious transactions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymeNOjSCFjjy",
        "outputId": "6f20bf12-b0d1-4d21-f26b-b4454e8f3c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 records for risk prediction\n",
            "Target distribution:\n",
            "is_floating_cash\n",
            "False    9499\n",
            "True      501\n",
            "Name: count, dtype: int64\n",
            "Original features requested: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed']\n",
            "Available features in data: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed']\n",
            "Target variable: is_floating_cash\n",
            "Final features being used: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed', 'amount_log', 'is_high_amount', 'is_high_latency', 'hour_of_day', 'day_of_week', 'is_weekend', 'high_risk_combo']\n",
            "Training random_forest model...\n",
            "Training set size: 10000 samples, 16 features\n",
            "Features used: ['amount', 'simulated_network_latency', 'transaction_type', 'recipient_type', 'recipient_bank_name_or_ewallet', 'floating_duration_minutes', 'is_fraudulent_attempt', 'is_cancellation', 'manual_escalation_needed', 'amount_log', 'is_high_amount', 'is_high_latency', 'hour_of_day', 'day_of_week', 'is_weekend', 'high_risk_combo']\n",
            "Class distribution: {False: np.int64(9499), True: np.int64(501)}\n",
            "\n",
            "üéØ Model Evaluation Results:\n",
            "Accuracy: 0.9145\n",
            "AUC-ROC: 0.9556\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.91      0.95      1900\n",
            "        True       0.36      0.92      0.52       100\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.68      0.92      0.74      2000\n",
            "weighted avg       0.96      0.91      0.93      2000\n",
            "\n",
            "\n",
            "üìä Top 10 Most Important Features:\n",
            "                           feature  importance\n",
            "5        floating_duration_minutes    0.836327\n",
            "1        simulated_network_latency    0.025686\n",
            "9                       amount_log    0.023548\n",
            "0                           amount    0.021637\n",
            "4   recipient_bank_name_or_ewallet    0.019914\n",
            "2                 transaction_type    0.019914\n",
            "12                     hour_of_day    0.016706\n",
            "3                   recipient_type    0.009177\n",
            "13                     day_of_week    0.007732\n",
            "8         manual_escalation_needed    0.007084\n",
            "Risk probability: 0.0185\n"
          ]
        }
      ],
      "source": [
        "# SAMPLE DEMO 2 (Risk Predictor)\n",
        "\n",
        "# Initialize predictor\n",
        "predictor = TRYBERiskPredictor(model_type='random_forest')\n",
        "\n",
        "# Load and train\n",
        "df = predictor.load_data(\"/content/drive/My Drive/transactions_fixed.csv\")\n",
        "df_processed = predictor.preprocess_data(df)\n",
        "model = predictor.train_model(df_processed)\n",
        "\n",
        "# Predict risk for new transaction (Complete sample matching your dataset)\n",
        "new_transaction = {\n",
        "    'transaction_id': 'TXN_2025_001234',\n",
        "    'user_id': 'USER_789012',\n",
        "    'timestamp_initiated': '2025-01-15 14:30:22',\n",
        "    'amount': 1500.0,\n",
        "    'transaction_type': 'Bank to e-Wallet',\n",
        "    'recipient_type': 'Individual',\n",
        "    'recipient_account_id': 'ACC_567890',\n",
        "    'recipient_bank_name_or_ewallet': 'GCash',\n",
        "    'device_id': 'DEVICE_345678',\n",
        "    'location_coordinates': '14.5995,120.9842',  # Manila coordinates\n",
        "    'simulated_network_latency': 800,\n",
        "    'status_timestamp_1': '2025-01-15 14:30:23',\n",
        "    'status_1': 'initiated',\n",
        "    'status_timestamp_2': '2025-01-15 14:30:25',\n",
        "    'status_2': 'processing',\n",
        "    'status_timestamp_3': '2025-01-15 14:30:28',\n",
        "    'status_3': 'verifying',\n",
        "    'status_timestamp_4': '2025-01-15 14:30:35',\n",
        "    'status_4': 'completed',\n",
        "    'expected_completion_time': '2025-01-15 14:31:00',\n",
        "    'floating_duration_minutes': 0,\n",
        "    'is_fraudulent_attempt': False,\n",
        "    'is_cancellation': False,\n",
        "    'is_retry_successful': True,\n",
        "    'manual_escalation_needed': False,\n",
        "    'transaction_types': 'Bank to e-Wallet',  # Alternative column name\n",
        "    'recipient_bank_name/e-wallet_name': 'GCash'  # Alternative column name\n",
        "}\n",
        "\n",
        "risk_probability = predictor.predict_risk(new_transaction)\n",
        "print(f\"Risk probability: {risk_probability:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVEePn-u8l6k"
      },
      "source": [
        "##**Aug. 11 Experiment** (USE THIS!!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZCt7FSJ8p0o"
      },
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# TRYBE Components ‚Äì **Revised**\n",
        "# -------------------------------------------------------------\n",
        "# This module updates your discrepancy‚Äëdetector and risk‚Äëpredictor\n",
        "# so they align 1‚Äëto‚Äë1 with **transactions_fixed.csv** while\n",
        "# remaining drop‚Äëin replacements for your existing notebook.\n",
        "#\n",
        "# Key tweaks\n",
        "# ----------\n",
        "# ‚Ä¢ **Schema auto‚Äëalignment** ‚Äì a lightweight `DataSchemaAligner`\n",
        "#   maps alternative column names to the canonical ones we use in\n",
        "#   code, so future header changes won‚Äôt break logic.\n",
        "# ‚Ä¢ **Cleaner rule logic** in `TRYBEDiscrepancyDetector` that now\n",
        "#   references the aligned columns directly.\n",
        "# ‚Ä¢ **Pre‚Äëprocessing hardening** in `TRYBERiskPredictor`: engineered\n",
        "#   features are created *after* schema alignment, categorical\n",
        "#   encodings reuse stored `LabelEncoder`s, and prediction gracefully\n",
        "#   handles unseen classes.\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 0. DATA‚ÄëSCHEMA ALIGNER\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "class DataSchemaAligner:\n",
        "    \"\"\"Map any alternative/legacy column names to our canonical names.\"\"\"\n",
        "\n",
        "    _NAME_MAP: Dict[str, List[str]] = {\n",
        "        # canonical                       aliases in raw CSVs\n",
        "        \"transaction_id\":                [\"txn_id\", \"id\"],\n",
        "        \"user_id\":                      [\"uid\"],\n",
        "        \"amount\":                       [\"txn_amount\"],\n",
        "        \"transaction_type\":             [\"transaction_types\", \"txn_type\"],\n",
        "        \"recipient_type\":               [],\n",
        "        \"status_4\":                     [\"final_status\", \"status_final\"],\n",
        "        \"is_floating_cash\":             [\"ground_truth_floating\"],\n",
        "        \"floating_duration_minutes\":    [\"float_minutes\"],\n",
        "        \"manual_escalation_needed\":     [\"escalate\"],\n",
        "        \"is_fraudulent_attempt\":        [\"fraud_flag\"],\n",
        "        \"simulated_network_latency\":    [\"network_latency\", \"latency_ms\"],\n",
        "        \"recipient_bank_name_or_ewallet\":[\"recipient_bank\", \"recipient_bank/e-wallet_name\"],\n",
        "        \"timestamp_initiated\":          [\"timestamp\", \"initiated_at\"],\n",
        "        \"is_cancellation\":             [\"cancel_flag\"],\n",
        "    }\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.original = df.copy()\n",
        "        self.aligned = self._align(df.copy())\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    def _align(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        rename_map: Dict[str, str] = {}\n",
        "        for canonical, aliases in self._NAME_MAP.items():\n",
        "            if canonical in df.columns:\n",
        "                continue  # already good\n",
        "            for alt in aliases:\n",
        "                if alt in df.columns:\n",
        "                    rename_map[alt] = canonical\n",
        "                    break\n",
        "        if rename_map:\n",
        "            df = df.rename(columns=rename_map)\n",
        "        return df\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    @property\n",
        "    def frame(self) -> pd.DataFrame:\n",
        "        return self.aligned\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# TRYBE DISCREPANCY DETECTOR ‚Ä¢ v6\n",
        "# ------------------------------------------------------------------\n",
        "class TRYBEDiscrepancyDetector:\n",
        "    \"\"\"\n",
        "    Data-backed detector: flag any transaction whose\n",
        "    `floating_duration_minutes` exceeds 10 min.\n",
        "\n",
        "    ‚Ä¢ Precision  ‚âà 0.34\n",
        "    ‚Ä¢ Recall     ‚âà 0.96\n",
        "    ‚Ä¢ Alerts     ‚âà 14 % of rows (1 400 / 10 000 in your sample)\n",
        "    \"\"\"\n",
        "\n",
        "    _THRESHOLD_MIN = 10   # <- tune here if business needs change\n",
        "\n",
        "    # --------------------------------------------------------------\n",
        "    def load_transaction_data(self, src):\n",
        "        import pandas as pd\n",
        "        raw = pd.read_csv(src) if isinstance(src, str) else src.copy()\n",
        "        self.df = DataSchemaAligner(raw).frame\n",
        "        print(f\"Loaded {len(self.df):,} transactions\")\n",
        "        return self.df\n",
        "\n",
        "    # --------------------------------------------------------------\n",
        "    def _is_floating(self, row) -> bool:\n",
        "        return row.get(\"floating_duration_minutes\", 0) > self._THRESHOLD_MIN\n",
        "\n",
        "    # --------------------------------------------------------------\n",
        "    def detect_discrepancies(self, df=None):\n",
        "        if df is None:\n",
        "            df = getattr(self, \"df\", None)\n",
        "            if df is None:\n",
        "                raise ValueError(\"Run load_transaction_data() first.\")\n",
        "        else:\n",
        "            df = DataSchemaAligner(df).frame\n",
        "\n",
        "        df[\"detected_discrepancy\"] = df[\"floating_duration_minutes\"] > self._THRESHOLD_MIN\n",
        "        flagged = int(df[\"detected_discrepancy\"].sum())\n",
        "        print(f\"Flagged {flagged:,}/{len(df):,} ‚Äì {flagged/len(df):.2%}\")\n",
        "\n",
        "        # Optional ground-truth metrics\n",
        "        if \"is_floating_cash\" in df.columns:\n",
        "            tp = ((df[\"detected_discrepancy\"]) &  df[\"is_floating_cash\"]).sum()\n",
        "            fp = flagged - tp\n",
        "            fn = ((~df[\"detected_discrepancy\"]) & df[\"is_floating_cash\"]).sum()\n",
        "            precision = tp / (tp + fp) if tp+fp else 0\n",
        "            recall    = tp / (tp + fn) if tp+fn else 0\n",
        "            print(f\"Precision: {precision:.3f} | Recall: {recall:.3f}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    # --------------------------------------------------------------\n",
        "    def get_flagged_transactions(self, df=None):\n",
        "        if df is None:\n",
        "            df = getattr(self, \"df\", None)\n",
        "            if df is None:\n",
        "                raise ValueError(\"Run detect_discrepancies() first.\")\n",
        "\n",
        "        cols = [\n",
        "            \"transaction_id\", \"user_id\", \"amount\", \"transaction_type\",\n",
        "            \"status_4\", \"floating_duration_minutes\"\n",
        "        ]\n",
        "        return df.loc[df[\"detected_discrepancy\"], [c for c in cols if c in df.columns]].copy()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. TRYBE RISK PREDICTOR (Revised)\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "class TRYBERiskPredictor:\n",
        "    \"\"\"Predict probability a transaction will float, with robust preprocessing.\"\"\"\n",
        "\n",
        "    def __init__(self, model_type: str = \"random_forest\"):\n",
        "        self.model_type = model_type\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders: Dict[str, LabelEncoder] = {}\n",
        "        self.model = None  # will be set in train_model\n",
        "        self.feature_cols: List[str] = []\n",
        "        self.target_col: str = \"is_floating_cash\"\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def load_data(self, file_or_df):\n",
        "        raw = pd.read_csv(file_or_df) if isinstance(file_or_df, str) else file_or_df.copy()\n",
        "        df = DataSchemaAligner(raw).frame\n",
        "        print(f\"Loaded {len(df):,} records | Floating‚Äëcash prevalence: {df[self.target_col].mean():.2%}\")\n",
        "        return df\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = DataSchemaAligner(df).frame.copy()\n",
        "\n",
        "        base_features = [\n",
        "            \"amount\", \"simulated_network_latency\", \"transaction_type\", \"recipient_type\",\n",
        "            \"recipient_bank_name_or_ewallet\", \"floating_duration_minutes\", \"is_fraudulent_attempt\",\n",
        "            \"is_cancellation\", \"manual_escalation_needed\",\n",
        "        ]\n",
        "        engineered = self._add_engineered_features(df)\n",
        "        self.feature_cols = [f for f in base_features + engineered if f in df.columns]\n",
        "\n",
        "        # missing value handling\n",
        "        for col in self.feature_cols:\n",
        "            if df[col].dtype == object or pd.api.types.is_categorical_dtype(df[col]):\n",
        "                df[col] = df[col].fillna(\"unknown\")\n",
        "            else:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "        # encode categoricals\n",
        "        for col in [\"transaction_type\", \"recipient_type\", \"recipient_bank_name_or_ewallet\"]:\n",
        "            if col in df.columns:\n",
        "                le = self.label_encoders.get(col, LabelEncoder())\n",
        "                df[col] = le.fit_transform(df[col].astype(str)) if col not in self.label_encoders else le.transform(df[col].astype(str))\n",
        "                self.label_encoders[col] = le\n",
        "\n",
        "        return df\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def _add_engineered_features(self, df: pd.DataFrame) -> List[str]:\n",
        "        new_cols: List[str] = []\n",
        "        if \"amount\" in df.columns:\n",
        "            df[\"amount_log\"] = np.log1p(df[\"amount\"])\n",
        "            df[\"is_high_amount\"] = (df[\"amount\"] > df[\"amount\"].quantile(0.9)).astype(int)\n",
        "            new_cols += [\"amount_log\", \"is_high_amount\"]\n",
        "\n",
        "        if \"simulated_network_latency\" in df.columns:\n",
        "            df[\"is_high_latency\"] = (df[\"simulated_network_latency\"] > 1_000).astype(int)\n",
        "            new_cols.append(\"is_high_latency\")\n",
        "\n",
        "        if \"timestamp_initiated\" in df.columns:\n",
        "            ts = pd.to_datetime(df[\"timestamp_initiated\"], errors=\"coerce\")\n",
        "            df[\"hour_of_day\"] = ts.dt.hour\n",
        "            df[\"day_of_week\"] = ts.dt.dayofweek\n",
        "            df[\"is_weekend\"] = ts.dt.dayofweek.isin([5, 6]).astype(int)\n",
        "            new_cols += [\"hour_of_day\", \"day_of_week\", \"is_weekend\"]\n",
        "\n",
        "        if {\"is_fraudulent_attempt\", \"manual_escalation_needed\"}.issubset(df.columns):\n",
        "            df[\"high_risk_combo\"] = (df[\"is_fraudulent_attempt\"] | df[\"manual_escalation_needed\"]).astype(int)\n",
        "            new_cols.append(\"high_risk_combo\")\n",
        "\n",
        "        return new_cols\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def _init_model(self):\n",
        "        if self.model_type == \"random_forest\":\n",
        "            return RandomForestClassifier(\n",
        "                n_estimators=150, max_depth=15, min_samples_split=10,\n",
        "                class_weight=\"balanced\", random_state=42\n",
        "            )\n",
        "        if self.model_type == \"logistic_regression\":\n",
        "            return LogisticRegression(max_iter=1500, class_weight=\"balanced\", random_state=42)\n",
        "        raise ValueError(f\"Unknown model_type: {self.model_type}\")\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def train_model(self, df: pd.DataFrame):\n",
        "        df_prep = self.preprocess(df)\n",
        "\n",
        "        X, y = df_prep[self.feature_cols], df_prep[self.target_col]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, stratify=y, random_state=42\n",
        "        )\n",
        "\n",
        "        self.scaler.fit(X_train)\n",
        "        X_train_s = self.scaler.transform(X_train)\n",
        "        X_test_s  = self.scaler.transform(X_test)\n",
        "\n",
        "        self.model = self._init_model()\n",
        "        self.model.fit(X_train_s, y_train)\n",
        "\n",
        "        self._evaluate(X_test_s, y_test)\n",
        "        return self.model\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def _evaluate(self, X_test, y_test):\n",
        "        preds      = self.model.predict(X_test)\n",
        "        pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        auc = roc_auc_score(y_test, pred_proba)\n",
        "        print(\"\\nModel evaluation ‚Üí Accuracy:\", f\"{acc:.4f}\", \"| AUC:\", f\"{auc:.4f}\")\n",
        "        print(classification_report(y_test, preds))\n",
        "\n",
        "    # ----------------------------------------------\n",
        "    def predict_risk(self, txn):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"Model not trained. Call train_model() first.\")\n",
        "\n",
        "        tx_df = pd.DataFrame([txn]) if isinstance(txn, dict) else txn.copy()\n",
        "        tx_df = self.preprocess(tx_df)  # uses stored encoders\n",
        "        avail  = [c for c in self.feature_cols if c in tx_df.columns]\n",
        "\n",
        "        # ensure same feature order / width as training\n",
        "        X = pd.DataFrame(0, index=tx_df.index, columns=self.feature_cols)\n",
        "        X[avail] = tx_df[avail]\n",
        "        X_s = self.scaler.transform(X)\n",
        "        proba = self.model.predict_proba(X_s)[:, 1]\n",
        "        return proba[0] if len(proba) == 1 else proba\n",
        "\n",
        "# --------------------------------------------------\n",
        "# OPTIONAL ‚Ä¢ Self-register this notebook cell as a module\n",
        "#           so later `import trybe_components_revised` works\n",
        "#           even though no file was written.\n",
        "import sys as _sys\n",
        "_sys.modules['trybe_components_revised'] = _sys.modules[__name__]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "ERZzFHcY9ll1",
        "outputId": "3a4c839f-116f-401d-9ffc-4ff433288aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10,000 transactions\n",
            "Flagged 1,413/10,000 ‚Äì 14.13%\n",
            "Precision: 0.342 | Recall: 0.964\n",
            "\n",
            "üîç Flagged transactions (top rows):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(f\\\"\\\\n\\ud83c\\udfaf Predicted floating-cash risk: {risk_prob:\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"transaction_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"71239c09-ef48-4796-a979-4d6f6e578c74\",\n          \"d16a8277-2f54-4fb9-a03a-0e9e95261d76\",\n          \"8a54c62c-8822-4824-a212-eb7e891dd706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"user_53523\",\n          \"user_8112\",\n          \"user_819448\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2901.3142957938526,\n        \"min\": 465.34,\n        \"max\": 8129.43,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          465.34,\n          3374.88,\n          2540.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transaction_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"QR Payment (Merchant)\",\n          \"Cash-In via Partner Outlet\",\n          \"Bank to e-Wallet (Maya)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status_4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Failed (Network Error)\",\n          \"Credit Confirmed (Recipient)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"floating_duration_minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1689,\n        \"min\": 18,\n        \"max\": 5386,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5386,\n          1165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ac1b4988-122c-482c-8410-6f60bd27d789\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>amount</th>\n",
              "      <th>transaction_type</th>\n",
              "      <th>status_4</th>\n",
              "      <th>floating_duration_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b9c8b5f7-e9g0-5d31-0b2d-4g5d6e7f8g9h</td>\n",
              "      <td>user_8</td>\n",
              "      <td>7497.00</td>\n",
              "      <td>Bills Payment (via Vybe Wallet)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>d16a8277-2f54-4fb9-a03a-0e9e95261d76</td>\n",
              "      <td>user_8112</td>\n",
              "      <td>3374.88</td>\n",
              "      <td>Cash-In via Partner Outlet</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>781ee456-11b3-40e1-b4f0-46654e528b17</td>\n",
              "      <td>user_9037</td>\n",
              "      <td>4393.18</td>\n",
              "      <td>Vybe Wallet to ShopeePay</td>\n",
              "      <td>Failed (Network Error)</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>51bf7284-90cd-493e-af38-9e5c7cf59795</td>\n",
              "      <td>user_22</td>\n",
              "      <td>7422.37</td>\n",
              "      <td>Bank to Bank (PESONet)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>53e37257-2e23-4482-aa0d-b4b9679f187a</td>\n",
              "      <td>user_132205</td>\n",
              "      <td>1545.96</td>\n",
              "      <td>Vybe Wallet to GCash</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8a54c62c-8822-4824-a212-eb7e891dd706</td>\n",
              "      <td>user_819448</td>\n",
              "      <td>2540.20</td>\n",
              "      <td>Bank to e-Wallet (Maya)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>25b96788-b4b0-4c8d-b7fc-4e4054238b7d</td>\n",
              "      <td>user_80562</td>\n",
              "      <td>2883.33</td>\n",
              "      <td>Bank to e-Wallet (ShopeePay)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>76472df3-2ed5-48b4-938a-3603b573685e</td>\n",
              "      <td>user_3</td>\n",
              "      <td>8129.43</td>\n",
              "      <td>QR Payment (Merchant)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>71239c09-ef48-4796-a979-4d6f6e578c74</td>\n",
              "      <td>user_53523</td>\n",
              "      <td>465.34</td>\n",
              "      <td>Bank to e-Wallet (Maya)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>5386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>5c0e1286-d249-4114-8f4f-d7486f03080e</td>\n",
              "      <td>user_5</td>\n",
              "      <td>465.91</td>\n",
              "      <td>Vybe Wallet to Bank (BPI)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1b4988-122c-482c-8410-6f60bd27d789')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac1b4988-122c-482c-8410-6f60bd27d789 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac1b4988-122c-482c-8410-6f60bd27d789');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6a9db4d9-3f29-4a7d-9e3e-9884cb327c5f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a9db4d9-3f29-4a7d-9e3e-9884cb327c5f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6a9db4d9-3f29-4a7d-9e3e-9884cb327c5f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          transaction_id      user_id   amount  \\\n",
              "3   b9c8b5f7-e9g0-5d31-0b2d-4g5d6e7f8g9h       user_8  7497.00   \n",
              "9   d16a8277-2f54-4fb9-a03a-0e9e95261d76    user_8112  3374.88   \n",
              "14  781ee456-11b3-40e1-b4f0-46654e528b17    user_9037  4393.18   \n",
              "18  51bf7284-90cd-493e-af38-9e5c7cf59795      user_22  7422.37   \n",
              "19  53e37257-2e23-4482-aa0d-b4b9679f187a  user_132205  1545.96   \n",
              "21  8a54c62c-8822-4824-a212-eb7e891dd706  user_819448  2540.20   \n",
              "30  25b96788-b4b0-4c8d-b7fc-4e4054238b7d   user_80562  2883.33   \n",
              "31  76472df3-2ed5-48b4-938a-3603b573685e       user_3  8129.43   \n",
              "35  71239c09-ef48-4796-a979-4d6f6e578c74   user_53523   465.34   \n",
              "37  5c0e1286-d249-4114-8f4f-d7486f03080e       user_5   465.91   \n",
              "\n",
              "                   transaction_type                      status_4  \\\n",
              "3   Bills Payment (via Vybe Wallet)  Credit Confirmed (Recipient)   \n",
              "9        Cash-In via Partner Outlet  Credit Confirmed (Recipient)   \n",
              "14         Vybe Wallet to ShopeePay        Failed (Network Error)   \n",
              "18           Bank to Bank (PESONet)  Credit Confirmed (Recipient)   \n",
              "19             Vybe Wallet to GCash  Credit Confirmed (Recipient)   \n",
              "21          Bank to e-Wallet (Maya)  Credit Confirmed (Recipient)   \n",
              "30     Bank to e-Wallet (ShopeePay)  Credit Confirmed (Recipient)   \n",
              "31            QR Payment (Merchant)  Credit Confirmed (Recipient)   \n",
              "35          Bank to e-Wallet (Maya)  Credit Confirmed (Recipient)   \n",
              "37        Vybe Wallet to Bank (BPI)  Credit Confirmed (Recipient)   \n",
              "\n",
              "    floating_duration_minutes  \n",
              "3                          44  \n",
              "9                        1165  \n",
              "14                         34  \n",
              "18                         53  \n",
              "19                         44  \n",
              "21                         46  \n",
              "30                         49  \n",
              "31                         18  \n",
              "35                       5386  \n",
              "37                         19  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model evaluation ‚Üí Accuracy: 0.9245 | AUC: 0.9532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      0.93      0.96      1900\n",
            "        True       0.37      0.73      0.49       100\n",
            "\n",
            "    accuracy                           0.92      2000\n",
            "   macro avg       0.68      0.83      0.73      2000\n",
            "weighted avg       0.95      0.92      0.94      2000\n",
            "\n",
            "\n",
            "üéØ Predicted floating-cash risk: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# 1Ô∏è‚É£  Discrepancy detection\n",
        "# --------------------------------------------------\n",
        "from trybe_components_revised import TRYBEDiscrepancyDetector\n",
        "\n",
        "detector = TRYBEDiscrepancyDetector()\n",
        "\n",
        "# Load + align the CSV once\n",
        "csv_path = pd.read_csv('/content/drive/My Drive/transactions_fixed.csv')\n",
        "df_txn   = detector.load_transaction_data(csv_path)\n",
        "\n",
        "# Run the detector\n",
        "df_flagged = detector.detect_discrepancies(df_txn)\n",
        "\n",
        "# Quick look at the first few discrepancies\n",
        "flagged_preview = detector.get_flagged_transactions(df_flagged)\n",
        "print(\"\\nüîç Flagged transactions (top rows):\")\n",
        "display(flagged_preview.head(10))      # use 'display' if running in Jupyter\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2Ô∏è‚É£  Risk prediction\n",
        "# --------------------------------------------------\n",
        "from trybe_components_revised import TRYBERiskPredictor\n",
        "\n",
        "predictor = TRYBERiskPredictor(model_type=\"random_forest\")\n",
        "\n",
        "# Re-use the same aligned dataframe (saves I/O) ‚Ä¶\n",
        "predictor.train_model(df_txn)\n",
        "\n",
        "# ‚Ä¶or you could reload from disk:\n",
        "# df_data = predictor.load_data(csv_path)\n",
        "# predictor.train_model(df_data)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3Ô∏è‚É£  Single-transaction inference\n",
        "# --------------------------------------------------\n",
        "# Use the *first* transaction as a demo input\n",
        "sample_txn = df_txn.iloc[0].to_dict()\n",
        "\n",
        "risk_prob = predictor.predict_risk(sample_txn)\n",
        "print(f\"\\nüéØ Predicted floating-cash risk: {risk_prob:.2%}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "EUanzmnT3RLA",
        "outputId": "3ad8aada-c3ff-4416-d783-a43cb8ef4bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10,000 transactions\n",
            "Flagged 1,413/10,000 ‚Äì 14.13%\n",
            "Precision: 0.342 | Recall: 0.964\n",
            "\n",
            "üîç Flagged transactions (top rows):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(f\\\"\\\\n\\ud83c\\udfaf Predicted floating-cash risk: {risk_prob:\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"transaction_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"71239c09-ef48-4796-a979-4d6f6e578c74\",\n          \"d16a8277-2f54-4fb9-a03a-0e9e95261d76\",\n          \"8a54c62c-8822-4824-a212-eb7e891dd706\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"user_53523\",\n          \"user_8112\",\n          \"user_819448\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2901.3142957938526,\n        \"min\": 465.34,\n        \"max\": 8129.43,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          465.34,\n          3374.88,\n          2540.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"transaction_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"QR Payment (Merchant)\",\n          \"Cash-In via Partner Outlet\",\n          \"Bank to e-Wallet (Maya)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status_4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Failed (Network Error)\",\n          \"Credit Confirmed (Recipient)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"floating_duration_minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1689,\n        \"min\": 18,\n        \"max\": 5386,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5386,\n          1165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f4f42c6d-b545-47d0-bc37-7a139973d0a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transaction_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>amount</th>\n",
              "      <th>transaction_type</th>\n",
              "      <th>status_4</th>\n",
              "      <th>floating_duration_minutes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b9c8b5f7-e9g0-5d31-0b2d-4g5d6e7f8g9h</td>\n",
              "      <td>user_8</td>\n",
              "      <td>7497.00</td>\n",
              "      <td>Bills Payment (via Vybe Wallet)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>d16a8277-2f54-4fb9-a03a-0e9e95261d76</td>\n",
              "      <td>user_8112</td>\n",
              "      <td>3374.88</td>\n",
              "      <td>Cash-In via Partner Outlet</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>781ee456-11b3-40e1-b4f0-46654e528b17</td>\n",
              "      <td>user_9037</td>\n",
              "      <td>4393.18</td>\n",
              "      <td>Vybe Wallet to ShopeePay</td>\n",
              "      <td>Failed (Network Error)</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>51bf7284-90cd-493e-af38-9e5c7cf59795</td>\n",
              "      <td>user_22</td>\n",
              "      <td>7422.37</td>\n",
              "      <td>Bank to Bank (PESONet)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>53e37257-2e23-4482-aa0d-b4b9679f187a</td>\n",
              "      <td>user_132205</td>\n",
              "      <td>1545.96</td>\n",
              "      <td>Vybe Wallet to GCash</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>8a54c62c-8822-4824-a212-eb7e891dd706</td>\n",
              "      <td>user_819448</td>\n",
              "      <td>2540.20</td>\n",
              "      <td>Bank to e-Wallet (Maya)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>25b96788-b4b0-4c8d-b7fc-4e4054238b7d</td>\n",
              "      <td>user_80562</td>\n",
              "      <td>2883.33</td>\n",
              "      <td>Bank to e-Wallet (ShopeePay)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>76472df3-2ed5-48b4-938a-3603b573685e</td>\n",
              "      <td>user_3</td>\n",
              "      <td>8129.43</td>\n",
              "      <td>QR Payment (Merchant)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>71239c09-ef48-4796-a979-4d6f6e578c74</td>\n",
              "      <td>user_53523</td>\n",
              "      <td>465.34</td>\n",
              "      <td>Bank to e-Wallet (Maya)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>5386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>5c0e1286-d249-4114-8f4f-d7486f03080e</td>\n",
              "      <td>user_5</td>\n",
              "      <td>465.91</td>\n",
              "      <td>Vybe Wallet to Bank (BPI)</td>\n",
              "      <td>Credit Confirmed (Recipient)</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f42c6d-b545-47d0-bc37-7a139973d0a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4f42c6d-b545-47d0-bc37-7a139973d0a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4f42c6d-b545-47d0-bc37-7a139973d0a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-11f1a65a-7909-41a5-a7b0-86110eff7b5d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11f1a65a-7909-41a5-a7b0-86110eff7b5d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-11f1a65a-7909-41a5-a7b0-86110eff7b5d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          transaction_id      user_id   amount  \\\n",
              "3   b9c8b5f7-e9g0-5d31-0b2d-4g5d6e7f8g9h       user_8  7497.00   \n",
              "9   d16a8277-2f54-4fb9-a03a-0e9e95261d76    user_8112  3374.88   \n",
              "14  781ee456-11b3-40e1-b4f0-46654e528b17    user_9037  4393.18   \n",
              "18  51bf7284-90cd-493e-af38-9e5c7cf59795      user_22  7422.37   \n",
              "19  53e37257-2e23-4482-aa0d-b4b9679f187a  user_132205  1545.96   \n",
              "21  8a54c62c-8822-4824-a212-eb7e891dd706  user_819448  2540.20   \n",
              "30  25b96788-b4b0-4c8d-b7fc-4e4054238b7d   user_80562  2883.33   \n",
              "31  76472df3-2ed5-48b4-938a-3603b573685e       user_3  8129.43   \n",
              "35  71239c09-ef48-4796-a979-4d6f6e578c74   user_53523   465.34   \n",
              "37  5c0e1286-d249-4114-8f4f-d7486f03080e       user_5   465.91   \n",
              "\n",
              "                   transaction_type                      status_4  \\\n",
              "3   Bills Payment (via Vybe Wallet)  Credit Confirmed (Recipient)   \n",
              "9        Cash-In via Partner Outlet  Credit Confirmed (Recipient)   \n",
              "14         Vybe Wallet to ShopeePay        Failed (Network Error)   \n",
              "18           Bank to Bank (PESONet)  Credit Confirmed (Recipient)   \n",
              "19             Vybe Wallet to GCash  Credit Confirmed (Recipient)   \n",
              "21          Bank to e-Wallet (Maya)  Credit Confirmed (Recipient)   \n",
              "30     Bank to e-Wallet (ShopeePay)  Credit Confirmed (Recipient)   \n",
              "31            QR Payment (Merchant)  Credit Confirmed (Recipient)   \n",
              "35          Bank to e-Wallet (Maya)  Credit Confirmed (Recipient)   \n",
              "37        Vybe Wallet to Bank (BPI)  Credit Confirmed (Recipient)   \n",
              "\n",
              "    floating_duration_minutes  \n",
              "3                          44  \n",
              "9                        1165  \n",
              "14                         34  \n",
              "18                         53  \n",
              "19                         44  \n",
              "21                         46  \n",
              "30                         49  \n",
              "31                         18  \n",
              "35                       5386  \n",
              "37                         19  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model evaluation ‚Üí Accuracy: 0.9245 | AUC: 0.9532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.99      0.93      0.96      1900\n",
            "        True       0.37      0.73      0.49       100\n",
            "\n",
            "    accuracy                           0.92      2000\n",
            "   macro avg       0.68      0.83      0.73      2000\n",
            "weighted avg       0.95      0.92      0.94      2000\n",
            "\n",
            "\n",
            "üéØ Predicted floating-cash risk: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# PKL\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1Ô∏è‚É£  Discrepancy detection\n",
        "# --------------------------------------------------\n",
        "from trybe_components_revised import TRYBEDiscrepancyDetector\n",
        "import pickle, pandas as pd\n",
        "\n",
        "detector = TRYBEDiscrepancyDetector()\n",
        "\n",
        "# Load + align the CSV once\n",
        "csv_path = pd.read_csv('/content/drive/My Drive/transactions_fixed.csv')\n",
        "df_txn   = detector.load_transaction_data(csv_path)\n",
        "\n",
        "# Run the detector\n",
        "df_flagged = detector.detect_discrepancies(df_txn)\n",
        "\n",
        "# Quick look at the first few discrepancies\n",
        "flagged_preview = detector.get_flagged_transactions(df_flagged)\n",
        "print(\"\\nüîç Flagged transactions (top rows):\")\n",
        "display(flagged_preview.head(10))      # use 'display' if running in Jupyter\n",
        "\n",
        "# Save detector as .pkl\n",
        "with open(\"trybe_discrepancy_detector.pkl\", \"wb\") as f:\n",
        "    pickle.dump(detector, f)\n",
        "\n",
        "# Reload detector\n",
        "with open(\"trybe_discrepancy_detector.pkl\", \"rb\") as f:\n",
        "    detector_loaded = pickle.load(f)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2Ô∏è‚É£  Risk prediction\n",
        "# --------------------------------------------------\n",
        "from trybe_components_revised import TRYBERiskPredictor\n",
        "\n",
        "predictor = TRYBERiskPredictor(model_type=\"random_forest\")\n",
        "\n",
        "# Train the model on the aligned dataframe\n",
        "predictor.train_model(df_txn)\n",
        "\n",
        "# Save predictor as .pkl\n",
        "with open(\"trybe_risk_predictor.pkl\", \"wb\") as f:\n",
        "    pickle.dump(predictor, f)\n",
        "\n",
        "# Reload predictor\n",
        "with open(\"trybe_risk_predictor.pkl\", \"rb\") as f:\n",
        "    predictor_loaded = pickle.load(f)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3Ô∏è‚É£  Single-transaction inference (with reloaded predictor)\n",
        "# --------------------------------------------------\n",
        "# Use the *first* transaction as a demo input\n",
        "sample_txn = df_txn.iloc[0].to_dict()\n",
        "\n",
        "risk_prob = predictor_loaded.predict_risk(sample_txn)\n",
        "print(f\"\\nüéØ Predicted floating-cash risk: {risk_prob:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
